{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import subprocess\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir /workspaces/capstone/Covid-Study-Data/Covid-Study-Data\n",
      "STATUS:\n",
      " 0 OUTPUT:\n",
      " \n"
     ]
    }
   ],
   "source": [
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "beginning = '2020-03-19'\n",
    "if not(os.path.exists('Covid-Study-Data')):\n",
    "    cmd = 'mkdir ' + os.path.join(os.getcwd(),'Covid-Study-Data')\n",
    "    print(cmd)\n",
    "    (status, output) = subprocess.getstatusoutput(cmd)    # try to make a new directory\n",
    "    print(\"STATUS:\\n\", status,\"OUTPUT:\\n\", output)                            # 0 implies error free!\n",
    "else:\n",
    "    print(\"'{}' already exists\".format(os.path.join(os.getcwd(), 'Covid-Study-Data')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('Covid-Study-Data')\n",
    "\n",
    "#Create new dictionary 'tickers' containing the assets we want to examine and their corresponding Yahoo Finance ticker\n",
    "tickers = {'EURUSD':'EURUSD=X','JPYUSD':'JPY=X','AUDUSD':'AUDUSD=X','CHFUSD':'CHF=X','CADUSD':'CAD=X','NOKUSD':'NOK=X',\n",
    " 'SEKUSD':'SEK=X','NZDUSD':'NZDUSD=X','RUBUSD':'RUBUSD=X','CNYUSD':'CNY=X','MXNUSD':'MXN=X','GBPUSD':'GBPUSD=X',\n",
    " 'BRLUSD':'BRL=X','DXY':'DX-Y.NYB','BTCUSD':'BTC-USD','GOLD':'GLD','S&P500':'^GSPC','DJIA':'^DJI','NASDAQ':'^IXIC'}\n",
    "\n",
    "#Each value in dictionary 'Tickers' is now a dataframe for the daily prices of the respective asset\n",
    "for key in tickers.keys():\n",
    "    tickers[key] = yf.download(tickers[key], start=beginning, end=today, progress=False)[[\"Adj Close\"]]\n",
    "    \n",
    "#Create dataframe 'Data' for the daily prices of all assets in this study\n",
    "data = pd.concat(list(tickers.values()), axis=1)\n",
    "data.columns = tickers.keys()\n",
    "\n",
    "#Code for web-scraping daily treasury yields from the FRED website\n",
    "baseurl = 'https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=on&txtcolor=%23444444&ts=12&tts=12&width=1168&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id='\n",
    "base2 = '&scale=left&cosd='\n",
    "base3 = '&coed='\n",
    "base4 = '&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=2&ost=-99999&oet=99999&mma=0&fml=a&fq=Daily&fam=avg&fgst=lin&fgsnd=2020-02-01&line_index=1&transformation=lin&vintage_date='\n",
    "base5 = '&revision_date='\n",
    "DGS10 = baseurl + 'DGS10' + base2 + beginning + base3 + today + base4 + str(today) + base5 + str(today) + '&nd=1962-01-02'\n",
    "DFII10 = baseurl + 'DFII10'+ base2 + beginning + base3 + today + base4 + str(today) + base5 + str(today) + '&nd=2003-01-02'\n",
    "DGS30 = baseurl + 'DGS30'+ base2 + beginning + base3 + today + base4 + str(today) + base5 + str(today) + '&nd=1977-02-15'\n",
    "DFII30 = baseurl + 'DFII30'+ base2 + beginning + base3 + today + base4 + str(today) + base5 + str(today) + '&nd=2010-02-22'\n",
    "DGS2 = baseurl + 'DGS2'+ base2 + beginning + base3 + today + base4 + str(today) + base5 + str(today) + '&nd=1976-06-01'\n",
    "\n",
    "#Dictionary similar to 'Tickers', this time for treasury yields\n",
    "datalinks = {'DGS10':DGS10,'DFII10':DFII10,'DGS30':DGS30,'DFII30':DFII30,'DGS2':DGS2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download CSV files for the treasury yield data\n",
    "for element in datalinks.keys():\n",
    "    destfile = os.path.join(os.getcwd(), element + '.csv')\n",
    "    fromfile = datalinks.get(element)\n",
    "    if not os.path.exists(destfile):\n",
    "        urllib.request.urlretrieve(fromfile, destfile)\n",
    "    else:\n",
    "        print(\"'{}' already exists\".format(destfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the treasury CSV files into dataframes\n",
    "DGS10 = pd.read_csv('DGS10.csv').set_index('DATE')\n",
    "DFII10 = pd.read_csv('DFII10.csv').set_index('DATE')\n",
    "DGS30 = pd.read_csv('DGS30.csv').set_index('DATE')\n",
    "DFII30 = pd.read_csv('DFII30.csv').set_index('DATE')\n",
    "DGS2 = pd.read_csv('DGS2.csv').set_index('DATE')\n",
    "\n",
    "#Create dataframe 'Tdata' which contains daily yields for all treasuries\n",
    "tdata = pd.concat([DGS10, DFII10,DGS30,DFII30,DGS2], axis=1)\n",
    "tdata = tdata[tdata.DGS10 != '.']\n",
    "tdata = tdata[tdata.DGS10 != ''].astype(float)\n",
    "\n",
    "#Join treasury data with the daily prices of all other assets in 'data'\n",
    "data = data.join(tdata)\n",
    "data.dropna(inplace=True)\n",
    "data.to_csv('Postcovid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Go over the same process, but this time for the 'Pre-COVID' period\n",
    "beginning = '2015-02-18'\n",
    "ending = '2020-02-19'\n",
    "\n",
    "tickers = {'EURUSD':'EURUSD=X','JPYUSD':'JPY=X','AUDUSD':'AUDUSD=X','CHFUSD':'CHF=X','CADUSD':'CAD=X','NOKUSD':'NOK=X',\n",
    " 'SEKUSD':'SEK=X','NZDUSD':'NZDUSD=X','RUBUSD':'RUBUSD=X','CNYUSD':'CNY=X','MXNUSD':'MXN=X','GBPUSD':'GBPUSD=X',\n",
    " 'BRLUSD':'BRL=X','DXY':'DX-Y.NYB','BTCUSD':'BTC-USD','GOLD':'GLD','S&P500':'^GSPC','DJIA':'^DJI','NASDAQ':'^IXIC'}\n",
    "\n",
    "for key in tickers.keys():\n",
    "    tickers[key] = yf.download(tickers[key], start=beginning, end=ending, progress=False)[[\"Adj Close\"]]\n",
    "    \n",
    "data = pd.concat(list(tickers.values()), axis=1)\n",
    "data.columns = tickers.keys()\n",
    "\n",
    "baseurl = 'https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=on&txtcolor=%23444444&ts=12&tts=12&width=1168&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id='\n",
    "base2 = '&scale=left&cosd='\n",
    "base3 = '&coed='\n",
    "base4 = '&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=2&ost=-99999&oet=99999&mma=0&fml=a&fq=Daily&fam=avg&fgst=lin&fgsnd=2020-02-01&line_index=1&transformation=lin&vintage_date='\n",
    "base5 = '&revision_date='\n",
    "DGS10 = baseurl + 'DGS10' + base2 + beginning + base3 + ending + base4 + str(ending) + base5 + str(ending) + '&nd=1962-01-02'\n",
    "DFII10 = baseurl + 'DFII10'+ base2 + beginning + base3 + ending + base4 + str(ending) + base5 + str(ending) + '&nd=2003-01-02'\n",
    "DGS30 = baseurl + 'DGS30'+ base2 + beginning + base3 + ending + base4 + str(ending) + base5 + str(ending) + '&nd=1977-02-15'\n",
    "DFII30 = baseurl + 'DFII30'+ base2 + beginning + base3 + ending + base4 + str(ending) + base5 + str(ending) + '&nd=2010-02-22'\n",
    "DGS2 = baseurl + 'DGS2'+ base2 + beginning + base3 + ending + base4 + str(ending) + base5 + str(ending) + '&nd=1976-06-01'\n",
    "datalinks = {'DGS10':DGS10,'DFII10':DFII10,'DGS30':DGS30,'DFII30':DFII30,'DGS2':DGS2}\n",
    "\n",
    "for element in datalinks.keys():\n",
    "    destfile = os.path.join(os.getcwd(), element + 'pre' + '.csv')\n",
    "    fromfile = datalinks.get(element)\n",
    "    if not os.path.exists(destfile):\n",
    "        urllib.request.urlretrieve(fromfile, destfile)\n",
    "    else:\n",
    "        print(\"'{}' already exists\".format(destfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "DGS10 = pd.read_csv('DGS10pre.csv').set_index('DATE')\n",
    "DFII10 = pd.read_csv('DFII10pre.csv').set_index('DATE')\n",
    "DGS30 = pd.read_csv('DGS30pre.csv').set_index('DATE')\n",
    "DFII30 = pd.read_csv('DFII30pre.csv').set_index('DATE')\n",
    "DGS2 = pd.read_csv('DGS2pre.csv').set_index('DATE')\n",
    "tdata = pd.concat([DGS10, DFII10,DGS30,DFII30,DGS2], axis=1)\n",
    "tdata = tdata[tdata.DGS10 != '.']\n",
    "tdata = tdata[tdata.DGS10 != ''].astype(float)\n",
    "data = data.join(tdata)\n",
    "data.dropna(inplace=True)\n",
    "data.to_csv('Precovid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Go over the same process, but this time for the entire timeperiod from 2015-2020\n",
    "beginning = '2015-02-18'\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "tickers = {'EURUSD':'EURUSD=X','JPYUSD':'JPY=X','AUDUSD':'AUDUSD=X','CHFUSD':'CHF=X','CADUSD':'CAD=X','NOKUSD':'NOK=X',\n",
    " 'SEKUSD':'SEK=X','NZDUSD':'NZDUSD=X','RUBUSD':'RUBUSD=X','CNYUSD':'CNY=X','MXNUSD':'MXN=X','GBPUSD':'GBPUSD=X',\n",
    " 'BRLUSD':'BRL=X','DXY':'DX-Y.NYB','BTCUSD':'BTC-USD','GOLD':'GLD','S&P500':'^GSPC','DJIA':'^DJI','NASDAQ':'^IXIC'}\n",
    "\n",
    "for key in tickers.keys():\n",
    "    tickers[key] = yf.download(tickers[key], start=beginning, end=today, progress=False)[[\"Adj Close\"]]\n",
    "data = pd.concat(list(tickers.values()), axis=1)\n",
    "data.columns = tickers.keys()\n",
    "\n",
    "baseurl = 'https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=on&txtcolor=%23444444&ts=12&tts=12&width=1168&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id='\n",
    "base2 = '&scale=left&cosd='\n",
    "base3 = '&coed='\n",
    "base4 = '&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=2&ost=-99999&oet=99999&mma=0&fml=a&fq=Daily&fam=avg&fgst=lin&fgsnd=2020-02-01&line_index=1&transformation=lin&vintage_date='\n",
    "base5 = '&revision_date='\n",
    "DGS10 = baseurl + 'DGS10' + base2 + beginning + base3 + today + base4 + str(today) + base5 + str(today) + '&nd=1962-01-02'\n",
    "DFII10 = baseurl + 'DFII10'+ base2 + beginning + base3 + today + base4 + str(today) + base5 + str(today) + '&nd=2003-01-02'\n",
    "DGS30 = baseurl + 'DGS30'+ base2 + beginning + base3 + today + base4 + str(today) + base5 + str(today) + '&nd=1977-02-15'\n",
    "DFII30 = baseurl + 'DFII30'+ base2 + beginning + base3 + today + base4 + str(today) + base5 + str(today) + '&nd=2010-02-22'\n",
    "DGS2 = baseurl + 'DGS2'+ base2 + beginning + base3 + today + base4 + str(today) + base5 + str(today) + '&nd=1976-06-01'\n",
    "datalinks = {'DGS10':DGS10,'DFII10':DFII10,'DGS30':DGS30,'DFII30':DFII30,'DGS2':DGS2}\n",
    "\n",
    "for element in datalinks.keys():\n",
    "    destfile = os.path.join(os.getcwd(), element + 'meta' + '.csv')\n",
    "    fromfile = datalinks.get(element)\n",
    "    urllib.request.urlretrieve(fromfile, destfile)\n",
    "    \n",
    "DGS10 = pd.read_csv('DGS10meta.csv').set_index('DATE')\n",
    "DFII10 = pd.read_csv('DFII10meta.csv').set_index('DATE')\n",
    "DGS30 = pd.read_csv('DGS30meta.csv').set_index('DATE')\n",
    "DFII30 = pd.read_csv('DFII30meta.csv').set_index('DATE')\n",
    "DGS2 = pd.read_csv('DGS2meta.csv').set_index('DATE')\n",
    "\n",
    "tdata = pd.concat([DGS10, DFII10,DGS30,DFII30,DGS2], axis=1)\n",
    "tdata = tdata[tdata.DGS10 != '.']\n",
    "tdata = tdata[tdata.DGS10 != ''].astype(float)\n",
    "data = data.join(tdata)\n",
    "data.dropna(inplace=True)\n",
    "data.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy.stats as stats            # Basic package for basic univariate regressions\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /workspaces/capstone/Covid-Study-Data\n"
     ]
    }
   ],
   "source": [
    "#Print current working directory\n",
    "print(\"Current directory:\" , os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m post\u001b[38;5;241m.\u001b[39mrename(columns \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDGS10\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUS10Y\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDGS2\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUS2Y\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDGS30\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUS30Y\u001b[39m\u001b[38;5;124m'\u001b[39m}, inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#Create new dataframes for daily percentage changes\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m prepct \u001b[38;5;241m=\u001b[39m \u001b[43mpre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpct_change\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m     15\u001b[0m postpct \u001b[38;5;241m=\u001b[39m post\u001b[38;5;241m.\u001b[39mpct_change()[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m     16\u001b[0m metapct \u001b[38;5;241m=\u001b[39m meta\u001b[38;5;241m.\u001b[39mpct_change()[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:12130\u001b[0m, in \u001b[0;36mNDFrame.pct_change\u001b[0;34m(self, periods, fill_method, limit, freq, **kwargs)\u001b[0m\n\u001b[1;32m  12128\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, col \u001b[38;5;129;01min\u001b[39;00m cols:\n\u001b[1;32m  12129\u001b[0m     mask \u001b[38;5;241m=\u001b[39m col\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m> 12130\u001b[0m     mask \u001b[38;5;241m=\u001b[39m mask[\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m~\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m :]\n\u001b[1;32m  12131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m  12132\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m  12133\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe default fill_method=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpad\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m  12134\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pct_change is deprecated and will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  12139\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m  12140\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:1229\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[1;32m   1144\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m-> 1229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "os.chdir('/workspaces/capstone/Covid-Study-Data')\n",
    "\n",
    "#Read CSV files from the file created in 'Study-Data'\n",
    "pre = pd.read_csv('Precovid.csv',index_col = [0],parse_dates = True)\n",
    "post = pd.read_csv('Postcovid.csv',index_col = [0],parse_dates = True)\n",
    "meta = pd.read_csv('data.csv',index_col = [0],parse_dates = True)\n",
    "\n",
    "#Rename columns for US Treasuries\n",
    "meta.rename(columns = {'DGS10':'US10Y','DGS2':'US2Y','DGS30':'US30Y'}, inplace = True)\n",
    "pre.rename(columns = {'DGS10':'US10Y','DGS2':'US2Y','DGS30':'US30Y'}, inplace = True)\n",
    "post.rename(columns = {'DGS10':'US10Y','DGS2':'US2Y','DGS30':'US30Y'}, inplace = True)\n",
    "\n",
    "#Create new dataframes for daily percentage changes\n",
    "prepct = pre.pct_change()[1:].astype(float)\n",
    "postpct = post.pct_change()[1:].astype(float)\n",
    "metapct = meta.pct_change()[1:].astype(float)\n",
    "\n",
    "#Replace infinite percentage change and nan values with 0\n",
    "postpct.replace([np.inf, -np.inf], 0,inplace=True)\n",
    "prepct.replace([np.inf, -np.inf], 0,inplace=True)\n",
    "metapct.replace([np.inf, -np.inf], 0,inplace=True)\n",
    "postpct.replace([np.nan],0,inplace=True)\n",
    "prepct.replace([np.nan],0,inplace=True)\n",
    "metapct.replace([np.nan],0,inplace=True)\n",
    "\n",
    "#x dataframes contain independent variables, y dataframes contain dependent variables\n",
    "#xmeta is a dataframe containing daily percentage changes for all assets considered dependent variables\n",
    "xmeta = metapct[['US2Y','US10Y','US30Y','DFII10','DFII30','S&P500','DJIA','NASDAQ','GOLD','BTCUSD']]\n",
    "xmeta = xmeta[1:]\n",
    "ymeta = metapct[['DXY','EURUSD','GBPUSD','CADUSD','CHFUSD','JPYUSD','AUDUSD','NZDUSD','NOKUSD','SEKUSD','MXNUSD','RUBUSD',\n",
    "                'BRLUSD','CNYUSD','BTCUSD','GOLD']][1:]\n",
    "\n",
    "#'pre' and 'post' correspond to the pre-COVID and post-COVID periods\n",
    "xpost = postpct[['US2Y','US10Y','US30Y','DFII10','DFII30','S&P500','DJIA','NASDAQ','GOLD','BTCUSD']]\n",
    "xpost = xpost[1:]\n",
    "xpre = prepct[['US2Y','US10Y','US30Y','DFII10','DFII30','S&P500','DJIA','NASDAQ','GOLD','BTCUSD']]\n",
    "xpre = xpre[1:]\n",
    "ypre = prepct[['DXY','EURUSD','GBPUSD','CADUSD','CHFUSD','JPYUSD','AUDUSD','NZDUSD','NOKUSD','SEKUSD','MXNUSD','RUBUSD',\n",
    "                'BRLUSD','CNYUSD','BTCUSD','GOLD']][1:]\n",
    "ypost = postpct[['DXY','EURUSD','GBPUSD','CADUSD','CHFUSD','JPYUSD','AUDUSD','NZDUSD','NOKUSD','SEKUSD','MXNUSD','RUBUSD',\n",
    "                'BRLUSD','CNYUSD','BTCUSD','GOLD']][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m meta\u001b[38;5;241m.\u001b[39mrename(columns \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDGS10\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUS10Y\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDGS2\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUS2Y\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDGS30\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUS30Y\u001b[39m\u001b[38;5;124m'\u001b[39m}, inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#Create new dataframe for percentage changes\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m metapct \u001b[38;5;241m=\u001b[39m \u001b[43mmeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpct_change\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m      9\u001b[0m metapct\u001b[38;5;241m.\u001b[39mreplace([np\u001b[38;5;241m.\u001b[39minf, \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf], \u001b[38;5;241m0\u001b[39m,inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m metapct\u001b[38;5;241m.\u001b[39mreplace([np\u001b[38;5;241m.\u001b[39mnan],\u001b[38;5;241m0\u001b[39m,inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:12130\u001b[0m, in \u001b[0;36mNDFrame.pct_change\u001b[0;34m(self, periods, fill_method, limit, freq, **kwargs)\u001b[0m\n\u001b[1;32m  12128\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, col \u001b[38;5;129;01min\u001b[39;00m cols:\n\u001b[1;32m  12129\u001b[0m     mask \u001b[38;5;241m=\u001b[39m col\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m> 12130\u001b[0m     mask \u001b[38;5;241m=\u001b[39m mask[\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m~\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m :]\n\u001b[1;32m  12131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m  12132\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m  12133\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe default fill_method=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpad\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m  12134\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pct_change is deprecated and will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  12139\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m  12140\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:1229\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[1;32m   1144\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m-> 1229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "#Read data from the csv file downloaded from FRED, this is for the same time periods previously examined\n",
    "meta = pd.read_csv('data.csv',index_col = [0],parse_dates = True)\n",
    "\n",
    "#Rename US treasury collumns\n",
    "meta.rename(columns = {'DGS10':'US10Y','DGS2':'US2Y','DGS30':'US30Y'}, inplace = True)\n",
    "\n",
    "#Create new dataframe for percentage changes\n",
    "metapct = meta.pct_change()[1:].astype(float)\n",
    "metapct.replace([np.inf, -np.inf], 0,inplace=True)\n",
    "metapct.replace([np.nan],0,inplace=True)\n",
    "\n",
    "#C is a new list containing four elements, each corresponding to the four key 'Dollar-Centric' trends found previously\n",
    "c = [['DXY','S&P500'],['DXY','US10Y'],['GOLD','S&P500'],['GOLD','US10Y']]\n",
    "\n",
    "#Show the rolling correlations for each relationship\n",
    "for item in c:   \n",
    "    corr = metapct[item[0]].rolling(20).corr(metapct[item[1]])\n",
    "    corr = corr.rolling(window = 40).mean()\n",
    "    corr.plot()\n",
    "    plt.axvline('2020-03-02',linewidth=10,alpha=0.4)\n",
    "    plt.title(f'{item[0]} & {item[1]} 20 day Rolling Correlation',fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xpre' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Create a similar list as the 'pvalues' list. This time, we will start by running an OLS regression for every\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#possible relationship between x and y variables in the pre-covid period.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#This is necessary to identify relationships that were significant in the pre-covid period but no longer in the post-covid period\u001b[39;00m\n\u001b[1;32m      5\u001b[0m pvaluespre \u001b[38;5;241m=\u001b[39m [DGS10, DFII10]\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mxpre\u001b[49m\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m ypre\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m!=\u001b[39m y:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xpre' is not defined"
     ]
    }
   ],
   "source": [
    "#Create a similar list as the 'pvalues' list. This time, we will start by running an OLS regression for every\n",
    "#possible relationship between x and y variables in the pre-covid period.\n",
    "#This is necessary to identify relationships that were significant in the pre-covid period but no longer in the post-covid period\n",
    "\n",
    "pvaluespre = [DGS10, DFII10]\n",
    "for x in xpre.keys():\n",
    "    for y in ypre.keys():\n",
    "        if x != y:\n",
    "            b = xpre[x]\n",
    "            b = sm.add_constant(b)\n",
    "            results = sm.OLS(ypre[y],b).fit()\n",
    "            if results.f_pvalue < 0.05:\n",
    "                pvaluespre.append([[x,y],results.f_pvalue,results.params[1]])\n",
    "for item in pvaluespre:\n",
    "    b = xpost[item[0][0]]\n",
    "    b = sm.add_constant(b)\n",
    "    model = sm.OLS(ypost[item[0][1]],b)\n",
    "    results = model.fit()\n",
    "    item.append([results.f_pvalue,results.params[1]])\n",
    "pvaluespre2 = [item for item in pvaluespre if item[3][0] >0.05]\n",
    "sorted_pre = sorted((value1,value2,value3,key) for (key,value1,value2,value3) in pvaluespre2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sorted_d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[43msorted_d\u001b[49m:   \n\u001b[1;32m      2\u001b[0m     corr \u001b[38;5;241m=\u001b[39m xmeta[item[\u001b[38;5;241m3\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39mrolling(\u001b[38;5;241m20\u001b[39m)\u001b[38;5;241m.\u001b[39mcorr(ymeta[item[\u001b[38;5;241m3\u001b[39m][\u001b[38;5;241m1\u001b[39m]])\n\u001b[1;32m      3\u001b[0m     corr \u001b[38;5;241m=\u001b[39m corr\u001b[38;5;241m.\u001b[39mrolling(window \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m40\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sorted_d' is not defined"
     ]
    }
   ],
   "source": [
    "for item in sorted_d:   \n",
    "    corr = xmeta[item[3][0]].rolling(20).corr(ymeta[item[3][1]])\n",
    "    corr = corr.rolling(window = 40).mean()\n",
    "    corr.plot()\n",
    "    plt.axvline('2020-03-02',linewidth=10,alpha=0.4)\n",
    "    plt.title(f'{item[3][0]} & {item[3][1]} 20 day Rolling Correlation',fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pvalues' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sorted_d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m((value1,value2,value3,key) \u001b[38;5;28;01mfor\u001b[39;00m (key,value1,value2,value3) \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpvalues\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pvalues' is not defined"
     ]
    }
   ],
   "source": [
    "sorted_d = sorted((value1,value2,value3,key) for (key,value1,value2,value3) in pvalues)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
